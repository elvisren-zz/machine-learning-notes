\documentclass[reqno]{book}

\usepackage{amssymb}
\usepackage{latexsym}



% algorithm
\usepackage{algpseudocode}
\usepackage[section]{algorithm}
\usepackage{algorithmicx}
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{float}

% math theorem, lemma, proof
\usepackage{amsthm}
%\theoremstyle{definition}
%\newtheorem{definition}{Definition}
%\newtheorem{theorem}{Theorem}

\usepackage{thmtools}
\declaretheorem{theorem}
\declaretheorem{definition}
\declaretheorem{example}
\declaretheorem{axiom}



% for mathematical integratoin
\usepackage{commath}


% for drawing beautiful math commutative diagram
% note:
%   it treat nodes as a matrix and use "&" to separate row and "\\" for line.
%   "'" change the label from above arrow to below arrow.
%   "l", "r" and "d" means move among matrix nodes.
\usepackage{tikz-cd}


% create index
\usepackage{mathtools}
\usepackage{makeidx}
\makeindex


\usepackage{listings}



% set font



%\usepackage[T1]{fontenc}
\usepackage{fontspec}


%\usepackage{kpfonts}
%\setmainfont{Verdana}
%\setmainfont{Times New Roman}
%\setmonofont{PragmataPro}
\usepackage[charter,adobe-utopia,uppercase=upright]{mathdesign}
%\usepackage{amsfonts}


% no space in itemize
\usepackage{enumitem}
\setenumerate{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=2pt}
\setitemize{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=2pt}
\setdescription{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=2pt}


% set line space
\usepackage{setspace}



% set page size
\usepackage{geometry}
%\geometry{a4paper}
\geometry{a4paper,top=2cm,bottom=2cm,left=2.5cm,right=2cm}


% set programming code highlight
% \usepackage[chapter]{minted}


% setup bibtex
\usepackage{cite}



% set toc and section level
\setcounter{secnumdepth}{7}
\setcounter{tocdepth}{7}



% customized commands
\newcommand\cindex[1]{\textcolor{blue}{\textbf{#1}}\index{#1}}
\newcommand\mathhilight[1]{\mathop{\bf #1\/}}


% set theory
\newcommand\powerset[1]{\mathcal{P}\left( #1 \right)}
\newcommand\range[1]{\mathbf{ran}(#1)}
\newcommand\domain[1]{\mathbf{dom}(#1)}
\newcommand\allordinals[0]{\mathbf{Ord}}
\newcommand\transfinitesequence[1]{\left< #1 \right>}
\newcommand\supremum[1]{\mathbf{sup} \set{#1}}
\newcommand\infimum[1]{\mathbf{inf} \set{#1}}



%linear algebra
\newcommand\nullspace[1]{\mathcal{N}(#1)}
\newcommand\rangespace[1]{\mathcal{R}(#1)}
\newcommand\absolutevalue[1]{\abs{#1}}
\newcommand\determinate[1]{\absolutevalue{#1}}
\newcommand\coordinate[1]{\sbr{#1}}
\newcommand\projection[2]{\mathbf{proj}_{#2} #1}


\newcommand\dimension[1]{\displaystyle \mathbf{dim}\left( #1 \right)}
\newcommand\rank[1]{\displaystyle \mathbf{rank}( #1 )}
\newcommand\innerproduct[2]{\left\langle \displaystyle #1, #2 \right\rangle}
\newcommand\trace[1]{\displaystyle \mathbf{tr}( #1 )}


\newcommand\adjugate[1]{\displaystyle \mathbf{adj} \displaystyle #1 }
\newcommand\cofactor[1]{\displaystyle \mathbf{cof} \displaystyle #1 }

\newcommand\columnvector[1]{\boldsymbol{#1}}


%probability
\newcommand\probability[1]{\mathop{\bf P\/}\displaystyle \left\{#1\right\}}
\newcommand\expect[1]{\mathop{\bf E\/}\displaystyle  \left[ #1 \right]}
\newcommand\variance[1]{\mathop{\bf Var\/}\displaystyle \left[ #1 \right]}
\newcommand\covariance[2]{\mathop{\bf Cov\/}\displaystyle \left(#1,#2 \right)}


% machine learning
\newcommand\subscription[2]{\boldsymbol{#1}^{(#2)}}



% start of the document  
\begin{document}

\title{Machine Learning}
\author{Elvis Ren}
\date{\today}

\maketitle
\tableofcontents

%\setcounter{page}{1}


\chapter{Set Theory}
\include{set_theory/st.1.axioms}
\include{set_theory/st.2.ordinalnumbers}
\include{set_theory/st.3.cardinalnumbers}


\chapter{Linear Algebra}
\include{linear_algebra/la.1.vector_space}
\include{linear_algebra/la.2.linear_transformation}
\include{linear_algebra/la.3.linear_equation}
\include{linear_algebra/la.4.determinants}
\include{linear_algebra/la.5.diagonalization}
\include{linear_algebra/la.6.inner_product_space}
\include{linear_algebra/la.7.operator}



\chapter{Matrix}
\include{matrix/math.2.matrix_differentiation}


\chapter{Probability}
\include{probability/p.1.random_variable}
\include{probability/p.2.conditional_expectation}


\chapter{Classic Machine Learning}
\include{machine_learning/classic.1.basics}
\include{machine_learning/classic.1.models}

\chapter {Deep Neural Network}
\include{deep_neural_network/dnn.1.intro}
\include{deep_neural_network/dnn.2.training}


\chapter{Reinforement Learning}
\include{reinforcement_learning/rl.1.bg}
\include{reinforcement_learning/rl.2.mdp}
\include{reinforcement_learning/rl.3.dp}
\include{reinforcement_learning/rl.4.mc} 
\include{reinforcement_learning/rl.5.td}
\include{reinforcement_learning/rl.6.nstep_sarsa}
\include{reinforcement_learning/rl.7.onpolicy_pred_fun_approx}
\include{reinforcement_learning/rl.8.eligibility_traces}
\include{reinforcement_learning/rl.9.policy_gradient}
\include{reinforcement_learning/rl.10.dyna}



\chapter{Others}
\include{others/other}


\bibliography{../../bibtex/library}{}
\bibliographystyle{alpha}


\printindex

\end{document}
